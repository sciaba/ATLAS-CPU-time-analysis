{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine results from different fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having fitted a set of speed factors from different but uniform samples, and knowing that the absolute scale is not determined, before comparing values from different samples it is necessary to rescale them to the same scale. My idea is to minimise the modulus of the difference between the first vector and the N-th vector multiplied by a factor, and rescale it accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in memory the test results from different files (assuming they are homogeneous, i.e. they are different measurements of the same quantities under the same conditions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_files = 10\n",
    "fact = dict()\n",
    "factors = defaultdict(dict)   # Dict containing all k_factors fitted for a given CPU, indexed by cpu type and file number\n",
    "factors_err = defaultdict(dict)   # Dict containing all k_factors fitted for a given CPU, indexed by cpu type and file number\n",
    "for i in range(n_files):\n",
    "    input_pattern = 'results_cputype_task_cpu_sub_%s_pile_0.001.csv'\n",
    "    f = open(input_pattern % (str(i)))\n",
    "    for line in f:\n",
    "        cpu, k, k_err = line.strip().split(',')\n",
    "        k = float(k)\n",
    "        factors[cpu][i] = k\n",
    "        factors_err[cpu][i] = k_err\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of \"rescaling functions\" are defined and tested to see how much they differ in their effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot(x, y):   # a special inner product that skips components where one of the vectors has a NaN\n",
    "    result = 0.\n",
    "    for i in range(len(x)):\n",
    "        if not np.isnan(x[i]) and not np.isnan(y[i]):\n",
    "            result += x[i] * y[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rescale_dist(x, y):   # rescales y such that the distance to x is minimised\n",
    "    y2 = y * x / x   # to put nan in elements where x has NaN\n",
    "    alpha = np.nansum(x * y) / np.nansum(y2 * y2)\n",
    "    return y * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rescale_first(x, y):   # rescales y such that it has the first element equal to x's one\n",
    "    return y / y[0] * x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rescale_mod(x):   # rescales x such that its Euclidean norm is one (NaN components are ignored)\n",
    "    n = len(x) - np.isnan(x).sum()\n",
    "    s = math.sqrt(np.nansum(x * x))\n",
    "    return x / s * math.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rescale_1norm(x):   # rescales x such that its l-1 norm is one \n",
    "    n = len(x) - np.isnan(x).sum()\n",
    "    s = np.nansum(np.fabs(x))\n",
    "    return x / s * n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the numbers in a matrix b where rows correspond to files and CPUs (mapped to numbers) to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmap = dict()   # mapping each CPU type to an integer starting from zero\n",
    "i = -1\n",
    "a = np.zeros((len(factors), n_files))   # a matrix with as many rows as CPU types and columns as files\n",
    "for c in factors.keys():\n",
    "    i += 1\n",
    "    cmap[c] = i\n",
    "    a[i] = [factors[c].setdefault(l, np.nan) for l in range(n_files)]   # a NaN is used if the CPU type is not present in file\n",
    "b = a.transpose()   # rows are files and columns are speed factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use as \"reference\" a vector where all CPU factors are one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref = np.ones(len(factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the speed factors according to different methods to make them \"averageable\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1 = np.empty_like(b)\n",
    "b2 = np.empty_like(b)\n",
    "b3 = np.empty_like(b)\n",
    "b4 = np.empty_like(b)\n",
    "b5 = np.empty_like(b)\n",
    "for i in range(n_files):\n",
    "    v = b[i]   # speed factors for file i\n",
    "    b1[i] = rescale_dist(ref, v)   \n",
    "    b2[i] = rescale_first(b[0], v)   # the first factor of the first file is used as reference (AV's suggestion)\n",
    "    b3[i] = rescale_mod(v)\n",
    "    b4[i] = rescale_dist(b[0], v)   # AS's initial idea\n",
    "    b5[i] = rescale_1norm(v)\n",
    "a1 = b1.transpose()\n",
    "a2 = b2.transpose()\n",
    "a3 = b3.transpose()\n",
    "a4 = b4.transpose()\n",
    "a5 = b5.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually inspect how the RMSes of the rescaled values for all files compare, for different rescaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0077 0.0069 0.0000 0.0079 0.0058 0.0090\n",
      "0.0064 0.0052 0.0049 0.0063 0.0026 0.0075\n",
      "0.0066 0.0077 0.0071 0.0083 0.0061 0.0091\n",
      "0.0074 0.0079 0.0042 0.0088 0.0048 0.0099\n",
      "0.0035 0.0044 0.0117 0.0040 0.0057 0.0040\n",
      "0.0049 0.0064 0.0085 0.0067 0.0041 0.0073\n",
      "0.0097 0.0103 0.0109 0.0110 0.0072 0.0118\n",
      "0.0116 0.0105 0.0113 0.0113 0.0082 0.0123\n",
      "0.0049 0.0055 0.0067 0.0062 0.0030 0.0072\n",
      "0.0063 0.0060 0.0085 0.0062 0.0057 0.0066\n",
      "0.0078 0.0095 0.0093 0.0090 0.0094 0.0086\n",
      "0.0106 0.0115 0.0080 0.0115 0.0103 0.0117\n",
      "0.0151 0.0164 0.0053 0.0165 0.0149 0.0167\n",
      "0.0125 0.0110 0.0136 0.0118 0.0091 0.0128\n",
      "0.0104 0.0102 0.0025 0.0111 0.0080 0.0121\n",
      "0.0196 0.0199 0.0197 0.0200 0.0193 0.0202\n",
      "0.0092 0.0087 0.0123 0.0091 0.0066 0.0098\n",
      "0.0109 0.0104 0.0037 0.0108 0.0094 0.0113\n",
      "0.0084 0.0082 0.0000 0.0084 0.0073 0.0087\n",
      "0.0139 0.0141 0.0108 0.0145 0.0121 0.0151\n",
      "0.0107 0.0121 0.0057 0.0128 0.0077 0.0136\n",
      "0.0081 0.0091 0.0093 0.0094 0.0070 0.0099\n",
      "0.0161 0.0135 0.0089 0.0143 0.0124 0.0152\n",
      "0.0093 0.0098 0.0038 0.0100 0.0088 0.0103\n",
      "0.0073 0.0089 0.0039 0.0088 0.0079 0.0090\n",
      "0.0096 0.0096 0.0099 0.0094 0.0099 0.0095\n",
      "0.0102 0.0105 0.0013 0.0111 0.0091 0.0118\n",
      "0.0102 0.0092 0.0039 0.0100 0.0073 0.0110\n",
      "0.0086 0.0085 0.0073 0.0094 0.0062 0.0104\n",
      "0.0074 0.0092 0.0145 0.0093 0.0069 0.0097\n",
      "0.0083 0.0091 0.0051 0.0099 0.0064 0.0108\n",
      "0.0039 0.0066 0.0068 0.0067 0.0052 0.0070\n",
      "0.0067 0.0062 0.0087 0.0069 0.0049 0.0079\n",
      "0.0092 0.0088 0.0088 0.0091 0.0075 0.0095\n",
      "0.0083 0.0056 nan 0.0051 0.0103 0.0048\n",
      "0.0000 0.0000 nan 0.0000 0.0000 0.0000\n",
      "0.0134 0.0143 0.0063 0.0150 0.0104 0.0157\n",
      "0.0075 0.0072 0.0069 0.0080 0.0053 0.0090\n",
      "0.0065 0.0049 nan 0.0055 0.0050 0.0063\n",
      "0.0094 0.0076 0.0045 0.0086 0.0052 0.0098\n",
      "0.0104 0.0103 0.0005 0.0109 0.0093 0.0116\n",
      "0.0151 0.0155 0.0121 0.0148 0.0171 0.0142\n",
      "0.0189 0.0170 0.0153 0.0183 0.0150 0.0195\n",
      "0.0097 0.0068 0.0019 0.0080 0.0066 0.0092\n",
      "0.0088 0.0090 0.0088 0.0096 0.0075 0.0104\n",
      "0.0122 0.0143 0.0058 0.0144 0.0122 0.0147\n",
      "0.0061 0.0060 0.0049 0.0069 0.0033 0.0080\n",
      "0.0511 0.0538 nan 0.0515 0.0587 0.0491\n",
      "0.0046 0.0078 0.0054 0.0073 0.0081 0.0070\n",
      "0.0048 0.0046 0.0068 0.0055 0.0021 0.0066\n",
      "0.0079 0.0071 0.0000 0.0064 0.0107 0.0058\n",
      "0.0087 0.0093 0.0037 0.0101 0.0063 0.0110\n",
      "0.0046 0.0016 nan 0.0023 0.0002 0.0031\n",
      "0.0128 0.0144 0.0061 0.0150 0.0107 0.0158\n",
      "0.0060 0.0050 0.0039 0.0061 0.0036 0.0073\n",
      "0.0091 0.0098 0.0072 0.0107 0.0059 0.0118\n",
      "0.0094 0.0069 0.0044 0.0079 0.0068 0.0090\n",
      "0.0110 0.0101 0.0003 0.0109 0.0091 0.0118\n",
      "0.0189 0.0187 0.0249 0.0182 0.0197 0.0178\n",
      "0.0101 0.0088 0.0077 0.0098 0.0061 0.0109\n",
      "0.0079 0.0097 0.0097 0.0100 0.0072 0.0105\n",
      "0.0075 0.0068 nan 0.0059 0.0126 0.0051\n",
      "0.0079 0.0055 0.0103 0.0066 0.0055 0.0078\n",
      "0.0112 0.0121 0.0182 0.0118 0.0113 0.0117\n",
      "0.0076 0.0097 0.0043 0.0094 0.0094 0.0093\n",
      "0.0068 0.0062 0.0075 0.0071 0.0046 0.0081\n",
      "0.0152 0.0140 0.0270 0.0139 0.0146 0.0139\n",
      "0.0085 0.0088 0.0074 0.0095 0.0057 0.0103\n",
      "0.0056 0.0058 0.0068 0.0061 0.0043 0.0067\n",
      "0.0376 0.0387 0.0228 0.0381 0.0396 0.0375\n",
      "0.0080 0.0098 0.0093 0.0095 0.0092 0.0095\n",
      "0.0082 0.0090 0.0070 0.0096 0.0074 0.0104\n",
      "0.0143 0.0130 0.0232 0.0137 0.0133 0.0145\n",
      "0.0116 0.0121 0.0049 0.0130 0.0086 0.0140\n",
      "0.0105 0.0088 0.0042 0.0093 0.0094 0.0100\n",
      "0.0079 0.0063 0.0087 0.0075 0.0047 0.0088\n",
      "0.0154 0.0151 0.0125 0.0155 0.0148 0.0161\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    print '%.4f %.4f %.4f %.4f %.4f %.4f' % (\n",
    "        np.nanstd(a[i]) / np.nanmean(a[i]),\n",
    "        np.nanstd(a1[i]) / np.nanmean(a1[i]),\n",
    "        np.nanstd(a2[i]) / np.nanmean(a2[i]),\n",
    "        np.nanstd(a3[i]) / np.nanmean(a3[i]),\n",
    "        np.nanstd(a4[i]) / np.nanmean(a4[i]),\n",
    "        np.nanstd(a5[i]) / np.nanmean(a5[i])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that any rescaling method strongly reduces the RMS, which is consistent with the fact that the speed factors fitted on different values don't have a priori the same scale. Therefore, rescaling is absolutely necessary if we want to combine different measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to see this is to calculate the sum of all the normalised rms and compare the totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789770530134 0.78962567895 nan 0.820041477796 0.70406326195 0.682472287992\n"
     ]
    }
   ],
   "source": [
    "t = 0.\n",
    "t1 = 0.\n",
    "t2 = 0.\n",
    "t3 = 0.\n",
    "t4 = 0.\n",
    "t5 = 0.\n",
    "\n",
    "for i in range(len(a)):\n",
    "    t += np.nanstd(a[i]) / np.nanmean(a[i])\n",
    "    t1 += np.nanstd(a1[i]) / np.nanmean(a1[i])\n",
    "    t2 += np.nanstd(a2[i]) / np.nanmean(a2[i])\n",
    "    t3 += np.nanstd(a3[i]) / np.nanmean(a3[i])\n",
    "    t4 += np.nanstd(a4[i]) / np.nanmean(a4[i])\n",
    "    t5 += np.nanstd(a4[i]) / np.nanmean(a5[i])\n",
    "print t, t1, t2, t3, t4, t5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These numbers show that all rescaling methods give similarly sized rms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually calculate the combined speed factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8489\n",
      "0.6896\n",
      "0.7781\n",
      "0.6641\n",
      "0.6792\n",
      "0.6980\n",
      "0.6634\n",
      "0.5614\n",
      "0.6513\n",
      "0.7001\n",
      "0.9648\n",
      "0.7779\n",
      "0.8099\n",
      "0.8402\n",
      "1.1666\n",
      "0.9088\n",
      "0.8789\n",
      "1.0376\n",
      "1.0779\n",
      "1.1355\n",
      "1.2053\n",
      "0.9408\n",
      "0.9012\n",
      "0.7630\n",
      "1.0987\n",
      "0.9048\n",
      "0.8968\n",
      "0.9172\n",
      "1.1782\n",
      "1.0479\n",
      "0.6636\n",
      "1.0399\n",
      "0.9646\n",
      "0.7942\n",
      "0.9659\n",
      "1.2298\n",
      "1.2756\n",
      "1.1353\n",
      "0.9866\n",
      "0.9696\n",
      "1.0092\n",
      "1.3934\n",
      "1.1014\n",
      "0.8670\n",
      "1.1570\n",
      "0.8698\n",
      "1.1622\n",
      "0.8058\n",
      "0.8994\n",
      "0.6589\n",
      "1.0147\n",
      "1.2249\n",
      "1.2349\n",
      "0.9550\n",
      "1.1271\n",
      "1.0497\n",
      "1.0792\n",
      "0.9950\n",
      "1.0470\n",
      "0.9750\n",
      "1.2564\n",
      "1.0520\n",
      "1.0713\n",
      "1.0617\n",
      "1.1303\n",
      "1.0815\n",
      "1.1596\n",
      "1.2947\n",
      "1.4621\n",
      "1.7292\n",
      "1.2354\n",
      "1.0873\n",
      "1.1409\n",
      "0.7079\n",
      "0.7795\n",
      "0.9065\n",
      "1.1696\n"
     ]
    }
   ],
   "source": [
    "output_file = 'results_cputype_task_cpu_pile_0.001.csv'\n",
    "with open(output_file, 'wb') as csvfile:\n",
    "    w = csv.writer(csvfile, delimiter=',')\n",
    "    for s in sorted(cmap.keys()):\n",
    "        print '%.4f' % np.nanmean(a5[cmap[s]])\n",
    "        w.writerow([s, np.nanmean(a5[cmap[s]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
